"""
Text validation utilities for IELTS submissions.
"""

import re
import logging
from typing import Dict, Any
from dataclasses import dataclass
from handlers.word_count_validator import enhanced_word_counter, format_word_count_result
from utils.text_analyzer import text_analyzer, format_analysis_summary

logger = logging.getLogger(__name__)


class TextValidationError(Exception):
    """Custom exception for text validation errors."""
    pass


@dataclass
class TaskRequirements:
    """
    Data class defining requirements for each IELTS task type.

    Python Concept: Dataclasses provide a clean way to define
    structured data with automatic __init__, __repr__, etc.
    """
    min_words: int
    max_words: int
    task_name: str
    description: str


# Task requirements configuration
TASK_REQUIREMENTS = {
    'task1': TaskRequirements(
        min_words=150,
        max_words=200,
        task_name='Task 1',
        description='Ú¯Ø±Ø§ÙØŒ Ø¬Ø¯ÙˆÙ„ØŒ Ù†Ù…ÙˆØ¯Ø§Ø± ÛŒØ§ ÙØ±Ø¢ÛŒÙ†Ø¯'
    ),
    'task2': TaskRequirements(
        min_words=250,
        max_words=350,
        task_name='Task 2',
        description='Ù…Ù‚Ø§Ù„Ù‡ Ù†Ø¸Ø±ÛŒ ÛŒØ§ Ø¨Ø­Ø«ÛŒ'
    )
}


def count_words(text: str) -> int:
    """
    Count words in text using proper word boundary detection.

    Python Concept: This uses regex to properly count words,
    handling punctuation and multiple spaces correctly.

    Args:
        text: Input text to count words in

    Returns:
        int: Number of words in text
    """
    # Remove extra whitespace and normalize
    text = re.sub(r'\s+', ' ', text.strip())

    # Split by word boundaries and filter empty strings
    words = re.findall(r'\b\w+\b', text)

    return len(words)


def check_text_language(text: str) -> Dict[str, Any]:
    """
    Check if text is primarily in English.

    Python Concept: This function uses character analysis
    to estimate if text is in English or other languages.

    Args:
        text: Text to analyze

    Returns:
        dict: Language analysis result
    """
    try:
        # Remove punctuation and spaces for analysis
        alpha_chars = re.sub(r'[^a-zA-Z\u0600-\u06FF]', '', text)

        if not alpha_chars:
            return {
                'is_english': False,
                'confidence': 0.0,
                'detected_language': 'unknown',
                'reason': 'Ù…ØªÙ† Ø´Ø§Ù…Ù„ Ø­Ø±ÙˆÙ Ù‚Ø§Ø¨Ù„ ØªØ´Ø®ÛŒØµ Ù†ÛŒØ³Øª'
            }

        # Count English characters
        english_chars = len(re.findall(r'[a-zA-Z]', alpha_chars))

        # Count Persian/Arabic characters
        persian_chars = len(re.findall(r'[\u0600-\u06FF]', alpha_chars))

        total_chars = len(alpha_chars)
        english_ratio = english_chars / total_chars if total_chars > 0 else 0
        persian_ratio = persian_chars / total_chars if total_chars > 0 else 0

        # Determine language
        if english_ratio >= 0.7:
            return {
                'is_english': True,
                'confidence': english_ratio,
                'detected_language': 'english',
                'english_ratio': english_ratio,
                'persian_ratio': persian_ratio
            }
        elif persian_ratio >= 0.7:
            return {
                'is_english': False,
                'confidence': persian_ratio,
                'detected_language': 'persian',
                'reason': 'Ù…ØªÙ† Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ Ù†ÙˆØ´ØªÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª',
                'english_ratio': english_ratio,
                'persian_ratio': persian_ratio
            }
        else:
            return {
                'is_english': False,
                'confidence': max(english_ratio, persian_ratio),
                'detected_language': 'mixed',
                'reason': 'Ù…ØªÙ† ØªØ±Ú©ÛŒØ¨ÛŒ Ø§Ø² Ø²Ø¨Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø®ØªÙ„Ù Ø§Ø³Øª',
                'english_ratio': english_ratio,
                'persian_ratio': persian_ratio
            }

    except Exception as e:
        logger.error(f"Error in language detection: {e}")
        return {
            'is_english': False,
            'confidence': 0.0,
            'detected_language': 'error',
            'reason': 'Ø®Ø·Ø§ Ø¯Ø± ØªØ´Ø®ÛŒØµ Ø²Ø¨Ø§Ù†'
        }


def check_text_quality(text: str) -> Dict[str, Any]:
    """
    Check basic text quality indicators.

    Args:
        text: Text to analyze

    Returns:
        dict: Quality analysis result
    """
    try:
        issues = []
        warnings = []

        # Check for minimum sentence structure
        sentences = re.split(r'[.!?]+', text)
        actual_sentences = [s.strip() for s in sentences if s.strip()]

        if len(actual_sentences) < 3:
            issues.append("Ù…ØªÙ† Ø´Ø§Ù…Ù„ Ú©Ù…ØªØ± Ø§Ø² 3 Ø¬Ù…Ù„Ù‡ Ø§Ø³Øª")

        # Check for excessive repetition
        words = text.lower().split()
        word_count = {}
        for word in words:
            if len(word) > 3:  # Only check meaningful words
                word_count[word] = word_count.get(word, 0) + 1

        # Check if any word is repeated too much
        total_words = len(words)
        for word, count in word_count.items():
            if count > max(3, total_words * 0.1):  # More than 10% or 3 times
                warnings.append(f"Ú©Ù„Ù…Ù‡ '{word}' Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ ØªÚ©Ø±Ø§Ø± Ø´Ø¯Ù‡ Ø§Ø³Øª")

        # Check for very short sentences
        short_sentences = [s for s in actual_sentences if len(s.split()) < 5]
        if len(short_sentences) > len(actual_sentences) * 0.5:
            warnings.append("Ø¨ÛŒØ´ Ø§Ø² Ù†ÛŒÙ…ÛŒ Ø§Ø² Ø¬Ù…Ù„Ø§Øª Ø¨Ø³ÛŒØ§Ø± Ú©ÙˆØªØ§Ù‡ Ù‡Ø³ØªÙ†Ø¯")

        # Check for proper capitalization
        if not re.search(r'[A-Z]', text):
            issues.append("Ù…ØªÙ† ÙØ§Ù‚Ø¯ Ø­Ø±ÙˆÙ Ø¨Ø²Ø±Ú¯ Ø§Ø³Øª")

        return {
            'has_issues': len(issues) > 0,
            'issues': issues,
            'warnings': warnings,
            'sentence_count': len(actual_sentences),
            'average_sentence_length': sum(len(s.split()) for s in actual_sentences) / len(
                actual_sentences) if actual_sentences else 0
        }

    except Exception as e:
        logger.error(f"Error in quality check: {e}")
        return {
            'has_issues': True,
            'issues': ['Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø±Ø±Ø³ÛŒ Ú©ÛŒÙÛŒØª Ù…ØªÙ†'],
            'warnings': [],
            'sentence_count': 0,
            'average_sentence_length': 0
        }


# Add these imports at the top of bot/handlers/text_validators.py:

from handlers.word_count_validator import enhanced_word_counter, format_word_count_result
from utils.text_analyzer import text_analyzer, format_analysis_summary


# Replace the existing validate_submission_text function with this enhanced version:

def validate_submission_text(text: str, task_type: str) -> Dict[str, Any]:
    """
    Enhanced comprehensive validation of submitted text for IELTS evaluation.

    Python Concept: This function now uses enhanced word counting and
    text analysis for much more detailed validation.

    Args:
        text: Submitted text to validate
        task_type: IELTS task type ('task1' or 'task2')

    Returns:
        dict: Enhanced validation result with detailed analysis

    Raises:
        TextValidationError: If validation fails
    """
    try:
        # Get task requirements
        requirements = TASK_REQUIREMENTS.get(task_type)
        if not requirements:
            raise TextValidationError(f"Ù†ÙˆØ¹ ØªØ³Ú© Ù†Ø§Ù…Ø¹ØªØ¨Ø±: {task_type}")

        # Basic text checks
        if not text or not text.strip():
            raise TextValidationError("Ù…ØªÙ† Ø§Ø±Ø³Ø§Ù„ÛŒ Ø®Ø§Ù„ÛŒ Ø§Ø³Øª")

        text = text.strip()

        # Check text length
        if len(text) < 50:
            raise TextValidationError("Ù…ØªÙ† Ø¨Ø³ÛŒØ§Ø± Ú©ÙˆØªØ§Ù‡ Ø§Ø³Øª (Ø­Ø¯Ø§Ù‚Ù„ 50 Ú©Ø§Ø±Ø§Ú©ØªØ±)")

        if len(text) > 5000:
            raise TextValidationError("Ù…ØªÙ† Ø¨Ø³ÛŒØ§Ø± Ø·ÙˆÙ„Ø§Ù†ÛŒ Ø§Ø³Øª (Ø­Ø¯Ø§Ú©Ø«Ø± 5000 Ú©Ø§Ø±Ø§Ú©ØªØ±)")

        # Enhanced word count validation
        word_count_result = enhanced_word_counter.validate_word_count(
            text=text,
            task_type=task_type,
            min_words=requirements.min_words,
            max_words=requirements.max_words
        )

        if not word_count_result.is_acceptable:
            # Create detailed error message from word count result
            error_msg = f"ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª Ù†Ø§Ù…Ù†Ø§Ø³Ø¨ ({word_count_result.total_words} Ú©Ù„Ù…Ù‡)"
            if word_count_result.suggestions:
                error_msg += f". {word_count_result.suggestions[0]}"
            raise TextValidationError(error_msg)

        # Check language (keeping existing function)
        language_result = check_text_language(text)
        if not language_result['is_english']:
            reason = language_result.get('reason', 'Ù…ØªÙ† Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ù†ÛŒØ³Øª')
            raise TextValidationError(f"Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† Ø±Ø§ Ø¨Ù‡ Ø²Ø¨Ø§Ù† Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯. {reason}")

        # Enhanced quality check with text analysis
        quality_result = check_text_quality(text)
        if quality_result['has_issues']:
            issues = quality_result['issues']
            raise TextValidationError(f"Ù…Ø´Ú©Ù„ Ø¯Ø± Ù…ØªÙ†: {', '.join(issues)}")

        # Check for placeholder text or common test phrases
        placeholder_patterns = [
            r'\b(lorem ipsum|test|testing|sample)\b',
            r'\b(asdf|qwerty|1234)\b',
            r'^[A-Za-z\s]{1,20}$'  # Very simple repetitive text
        ]

        for pattern in placeholder_patterns:
            if re.search(pattern, text.lower()):
                raise TextValidationError("Ù…ØªÙ† Ø§Ø±Ø³Ø§Ù„ÛŒ Ø¨Ù‡ Ù†Ø¸Ø± ØªØ³ØªÛŒ ÛŒØ§ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª. Ù„Ø·ÙØ§Ù‹ Ù…ØªÙ† ÙˆØ§Ù‚Ø¹ÛŒ Ø§Ø±Ø³Ø§Ù„ Ú©Ù†ÛŒØ¯")

        # Perform comprehensive text analysis
        analysis_result = text_analyzer.perform_complete_analysis(text, task_type)

        # Success - return enhanced validation result
        return {
            'is_valid': True,
            'word_count': word_count_result.total_words,
            'task_type': task_type,
            'task_name': requirements.task_name,
            'character_count': len(text),
            'language_analysis': language_result,
            'quality_analysis': quality_result,
            'word_count_analysis': word_count_result,
            'text_analysis': analysis_result,
            'meets_requirements': True,
            'validation_message': f"Ù…ØªÙ† Ù…Ø¹ØªØ¨Ø± - {word_count_result.total_words} Ú©Ù„Ù…Ù‡ Ø¨Ø±Ø§ÛŒ {requirements.task_name}",
            'detailed_word_count_summary': format_word_count_result(word_count_result, task_type),
            'detailed_analysis_summary': format_analysis_summary(analysis_result, task_type)
        }

    except TextValidationError:
        # Re-raise validation errors
        raise

    except Exception as e:
        logger.error(f"Unexpected error in enhanced text validation: {e}")
        raise TextValidationError("Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ù…ØªÙ†")


def get_enhanced_validation_summary(validation_result: Dict[str, Any]) -> str:
    """
    Generate enhanced validation summary with word count and text analysis.

    Args:
        validation_result: Enhanced validation result

    Returns:
        str: Comprehensive validation summary in Persian
    """
    try:
        if not validation_result.get('is_valid', False):
            return "Ù…ØªÙ† Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª"

        summary = "âœ… **Ù…ØªÙ† Ù…Ø¹ØªØ¨Ø± Ùˆ Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ**\n\n"

        # Add word count summary
        if 'detailed_word_count_summary' in validation_result:
            summary += validation_result['detailed_word_count_summary'] + "\n\n"

        # Add text analysis summary
        if 'detailed_analysis_summary' in validation_result:
            summary += validation_result['detailed_analysis_summary']

        return summary

    except Exception as e:
        logger.error(f"Error generating enhanced validation summary: {e}")
        return "Ø®Ø·Ø§ Ø¯Ø± ØªÙˆÙ„ÛŒØ¯ Ø®Ù„Ø§ØµÙ‡ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ"


def get_task_requirements_info(task_type: str) -> Dict[str, Any]:
    """
    Get detailed information about task requirements.

    Args:
        task_type: IELTS task type

    Returns:
        dict: Task requirements information
    """
    requirements = TASK_REQUIREMENTS.get(task_type)
    if not requirements:
        return {}

    return {
        'task_type': task_type,
        'task_name': requirements.task_name,
        'description': requirements.description,
        'min_words': requirements.min_words,
        'max_words': requirements.max_words,
        'recommended_range': f"{requirements.min_words}-{requirements.max_words} Ú©Ù„Ù…Ù‡"
    }


def format_validation_summary(validation_result: Dict[str, Any]) -> str:
    """
    Format validation result into a readable Persian summary.

    Args:
        validation_result: Result from validate_submission_text

    Returns:
        str: Formatted summary in Persian
    """
    try:
        if not validation_result.get('is_valid', False):
            return "Ù…ØªÙ† Ù†Ø§Ù…Ø¹ØªØ¨Ø± Ø§Ø³Øª"

        word_count = validation_result.get('word_count', 0)
        task_name = validation_result.get('task_name', 'Ù†Ø§Ù…Ø´Ø®Øµ')
        character_count = validation_result.get('character_count', 0)

        summary = f"""âœ… **Ù…ØªÙ† Ù…Ø¹ØªØ¨Ø±**

ðŸ“ **Ù†ÙˆØ¹ ØªØ³Ú©**: {task_name}
ðŸ“Š **ØªØ¹Ø¯Ø§Ø¯ Ú©Ù„Ù…Ø§Øª**: {word_count}
ðŸ“ **ØªØ¹Ø¯Ø§Ø¯ Ú©Ø§Ø±Ø§Ú©ØªØ±**: {character_count}

ðŸ” **ÙˆØ¶Ø¹ÛŒØª Ø¨Ø±Ø±Ø³ÛŒ**:
â€¢ Ø·ÙˆÙ„ Ù…ØªÙ†: Ù…Ù†Ø§Ø³Ø¨
â€¢ Ø²Ø¨Ø§Ù† Ù†Ú¯Ø§Ø±Ø´: Ø§Ù†Ú¯Ù„ÛŒØ³ÛŒ
â€¢ Ú©ÛŒÙÛŒØª Ú©Ù„ÛŒ: Ù‚Ø§Ø¨Ù„ Ù‚Ø¨ÙˆÙ„

âœ… **Ø¢Ù…Ø§Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ AI**"""

        # Add warnings if any
        quality_analysis = validation_result.get('quality_analysis', {})
        warnings = quality_analysis.get('warnings', [])

        if warnings:
            summary += f"\n\nâš ï¸ **Ù†Ú©Ø§Øª Ø¨Ù‡Ø¨ÙˆØ¯**:\n"
            for warning in warnings[:3]:  # Limit to 3 warnings
                summary += f"â€¢ {warning}\n"

        return summary

    except Exception as e:
        logger.error(f"Error formatting validation summary: {e}")
        return "Ø®Ù„Ø§ØµÙ‡ Ø§Ø¹ØªØ¨Ø§Ø±Ø³Ù†Ø¬ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³Øª"


def get_improvement_suggestions(text: str, task_type: str) -> Dict[str, Any]:
    """
    Provide suggestions for improving the submitted text.

    Args:
        text: Original text
        task_type: IELTS task type

    Returns:
        dict: Improvement suggestions
    """
    try:
        suggestions = []
        priorities = []

        requirements = TASK_REQUIREMENTS.get(task_type)
        if not requirements:
            return {'suggestions': [], 'priorities': []}

        word_count = count_words(text)

        # Word count suggestions
        if word_count < requirements.min_words:
            shortfall = requirements.min_words - word_count
            priorities.append(f"Ø§ÙØ²Ø§ÛŒØ´ {shortfall} Ú©Ù„Ù…Ù‡ Ø¯ÛŒÚ¯Ø±")
            suggestions.append("Ù…ØªÙ† Ø±Ø§ Ú¯Ø³ØªØ±Ø´ Ø¯Ù‡ÛŒØ¯ Ùˆ Ø¬Ø²Ø¦ÛŒØ§Øª Ø¨ÛŒØ´ØªØ±ÛŒ Ø§Ø¶Ø§ÙÙ‡ Ú©Ù†ÛŒØ¯")

        elif word_count > requirements.max_words + 50:
            excess = word_count - requirements.max_words
            suggestions.append(f"Ù…ØªÙ† {excess} Ú©Ù„Ù…Ù‡ Ø¨ÛŒØ´ Ø§Ø² Ø­Ø¯ ØªÙˆØµÛŒÙ‡ Ø´Ø¯Ù‡ Ø§Ø³Øª - Ø³Ø¹ÛŒ Ú©Ù†ÛŒØ¯ Ù…Ø®ØªØµØ±ØªØ± Ø¨Ø§Ø´ÛŒØ¯")

        # Check sentence variety
        sentences = re.split(r'[.!?]+', text)
        actual_sentences = [s.strip() for s in sentences if s.strip()]

        if len(actual_sentences) < 5:
            suggestions.append("ØªØ¹Ø¯Ø§Ø¯ Ø¬Ù…Ù„Ø§Øª Ø±Ø§ Ø§ÙØ²Ø§ÛŒØ´ Ø¯Ù‡ÛŒØ¯ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ØªØ± Ù†Ø´Ø§Ù† Ø¯Ø§Ø¯Ù† ØªÙ†ÙˆØ¹ Ú¯Ø±Ø§Ù…Ø±ÛŒ")

        # Check for complex sentences
        complex_sentence_indicators = ['because', 'although', 'however', 'furthermore', 'moreover']
        has_complex = any(indicator in text.lower() for indicator in complex_sentence_indicators)

        if not has_complex:
            suggestions.append("Ø§Ø² Ú©Ù„Ù…Ø§Øª Ø±Ø¨Ø· Ù¾ÛŒÚ†ÛŒØ¯Ù‡â€ŒØªØ±ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (however, furthermore, nevertheless)")

        # Task-specific suggestions
        if task_type == 'task1':
            data_words = ['increase', 'decrease', 'rose', 'fell', 'peak', 'trough', 'trend']
            has_data_language = any(word in text.lower() for word in data_words)

            if not has_data_language:
                suggestions.append("Ø§Ø² ÙˆØ§Ú˜Ú¯Ø§Ù† ØªØ®ØµØµÛŒ ØªÙˆØµÛŒÙ Ø¯Ø§Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†ÛŒØ¯ (increase, decrease, peak, etc.)")

        elif task_type == 'task2':
            opinion_words = ['believe', 'think', 'opinion', 'argue', 'suggest', 'conclude']
            has_opinion_language = any(word in text.lower() for word in opinion_words)

            if not has_opinion_language:
                suggestions.append("Ù†Ø¸Ø±Ø§Øª Ø´Ø®ØµÛŒ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ø§ Ú©Ù„Ù…Ø§Øª Ù…Ù†Ø§Ø³Ø¨ Ø¨ÛŒØ§Ù† Ú©Ù†ÛŒØ¯ (I believe, In my opinion, etc.)")

        return {
            'suggestions': suggestions,
            'priorities': priorities,
            'total_suggestions': len(suggestions),
            'has_priorities': len(priorities) > 0
        }

    except Exception as e:
        logger.error(f"Error generating improvement suggestions: {e}")
        return {
            'suggestions': [],
            'priorities': [],
            'total_suggestions': 0,
            'has_priorities': False
        }